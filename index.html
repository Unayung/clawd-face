<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no, viewport-fit=cover">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="mobile-web-app-capable" content="yes">
<meta name="theme-color" content="#e0c3fc">
<title>Clawd Face</title>
<style>
  * { margin: 0; padding: 0; box-sizing: border-box; }
  body {
    background: linear-gradient(135deg, #e0c3fc 0%, #8ec5fc 50%, #f5d5e0 100%);
    font-family: 'Courier New', 'Menlo', monospace;
    height: 100vh; width: 100vw;
    overflow: hidden;
    -webkit-tap-highlight-color: transparent;
  }

  /* â”€â”€ Status badge â”€â”€ */
  #status-bar {
    position: fixed; top: 0.8rem; right: 0.8rem; z-index: 100;
    display: flex; flex-direction: column; gap: 0.3rem;
    align-items: flex-end;
  }
  .status-badge {
    padding: 0.3em 0.8em; border-radius: 1em;
    font-size: 0.75rem; white-space: nowrap;
    background: rgba(255,255,255,0.7);
    transition: opacity 0.3s;
  }
  .status-badge.ok { color: #59c97a; }
  .status-badge.err { color: #e85d72; }
  .status-badge.warn { color: #f97316; }

  /* â”€â”€ Bottom bar â”€â”€ */
  #bottom-bar {
    position: fixed; bottom: 0; left: 0; right: 0;
    display: flex; align-items: center; gap: 0.6rem;
    padding: 0.8rem 1.2rem;
    padding-bottom: calc(0.8rem + env(safe-area-inset-bottom, 0px));
    background: rgba(255,255,255,0.75);
    backdrop-filter: blur(12px);
    -webkit-backdrop-filter: blur(12px);
    z-index: 50;
    border-top: 1px solid rgba(142,120,190,0.2);
    transform: translateY(100%);
    transition: transform 0.3s ease;
  }
  #bottom-bar.visible { transform: translateY(0); }

  /* â”€â”€ Chat input â”€â”€ */
  #chat-input {
    flex: 1; display: none;
    background: rgba(255,255,255,0.7);
    border: 1px solid rgba(142,120,190,0.3);
    border-radius: 1.5rem; padding: 0.7rem 1.2rem;
    color: #4a3f5c; font-family: inherit;
    font-size: 1rem; outline: none;
    min-width: 0;
  }
  #chat-input:focus { border-color: rgba(142,120,190,0.6); }
  #chat-input::placeholder { color: #a89cc0; }

  /* â”€â”€ Buttons â”€â”€ */
  .bar-btn {
    width: 44px; height: 44px; border-radius: 50%; border: none;
    background: rgba(142,120,190,0.2); color: #7a6a9a;
    font-size: 1.2rem; cursor: pointer;
    display: none; align-items: center; justify-content: center;
    transition: background 0.2s;
    flex-shrink: 0;
  }
  .bar-btn:hover { background: rgba(142,120,190,0.35); }
  .bar-btn:disabled { opacity: 0.4; cursor: default; }
  .bar-btn.active { background: rgba(229,62,62,0.3); color: #e53e3e; }

  /* â”€â”€ Demo hint (no features) â”€â”€ */
  #demo-hint {
    position: fixed; bottom: 1.5rem; left: 0; right: 0;
    text-align: center; color: rgba(100,80,140,0.5);
    font-size: 0.8rem; pointer-events: none;
    transition: opacity 0.3s;
  }

  /* â”€â”€ User message bubble â”€â”€ */
  #bubble {
    position: fixed;
    top: 8vh;
    max-width: 60vw;
    padding: 1.2em 1.8em;
    background: rgba(255,255,255,0.85);
    color: #4a3f5c;
    border-radius: 1.5em;
    font-size: clamp(0.9rem, 2.2vw, 1.5rem);
    line-height: 1.5;
    text-align: left;
    opacity: 0;
    transition: opacity 0.4s ease;
    z-index: 10;
    pointer-events: none;
    font-family: inherit;
    box-shadow: 0 4px 20px rgba(142,120,190,0.15);
  }
  #bubble.right {
    right: 4vw;
    left: auto;
  }
  #bubble.right::after {
    content: '';
    position: absolute;
    top: 50%;
    right: -18px;
    transform: translateY(-50%);
    border-top: 12px solid transparent;
    border-bottom: 12px solid transparent;
    border-left: 20px solid rgba(255,255,255,0.85);
  }
  #bubble.left {
    left: 4vw;
    right: auto;
  }
  #bubble.left::after {
    content: '';
    position: absolute;
    top: 50%;
    left: -18px;
    transform: translateY(-50%);
    border-top: 12px solid transparent;
    border-bottom: 12px solid transparent;
    border-right: 20px solid rgba(255,255,255,0.85);
  }
  #bubble.visible {
    opacity: 1;
  }
</style>
</head>
<body>

<!-- Face engine -->
<script src="face.js"></script>

<!-- User message bubble -->
<div id="bubble"></div>

<!-- Status badges -->
<div id="status-bar">
  <div id="status-gw" class="status-badge" style="display:none"></div>
  <div id="status-server" class="status-badge" style="display:none"></div>
</div>

<!-- Bottom bar (hidden until features detected) -->
<div id="bottom-bar">
  <button id="ptt-btn" class="bar-btn" title="Push to Talk">ðŸŽ¤</button>
  <input id="chat-input" type="text" placeholder="Say something..." autocomplete="off" enterkeyhint="send" />
  <button id="send-btn" class="bar-btn" title="Send">âž¤</button>
</div>

<!-- Demo hint (shown when no features) -->
<div id="demo-hint">tap anywhere to cycle expressions Â· press F for fullscreen</div>

<!-- Clawdbot integration -->
<script src="clawdbot.js"></script>

<script>
(() => {
  // â”€â”€ Elements â”€â”€
  const statusGw = document.getElementById('status-gw');
  const statusServer = document.getElementById('status-server');
  const bottomBar = document.getElementById('bottom-bar');
  const chatInput = document.getElementById('chat-input');
  const sendBtn = document.getElementById('send-btn');
  const pttBtn = document.getElementById('ptt-btn');
  const demoHint = document.getElementById('demo-hint');
  const bubbleEl = document.getElementById('bubble');

  // â”€â”€ User message bubble â”€â”€
  let bubbleTimeout = null;
  function showBubble(text, duration) {
    clearTimeout(bubbleTimeout);
    bubbleEl.classList.remove('visible', 'left', 'right');
    const side = Math.random() < 0.5 ? 'left' : 'right';
    bubbleEl.classList.add(side);
    bubbleEl.textContent = text;
    requestAnimationFrame(() => {
      bubbleEl.classList.add('visible');
    });
    bubbleTimeout = setTimeout(() => {
      bubbleEl.classList.remove('visible');
    }, duration || 8000);
  }

  // â”€â”€ Feature flags â”€â”€
  let hasServer = false;    // server.js running (PTT + TTS available)
  let hasGateway = false;   // Clawdbot WS connected (chat available)
  let bot = null;

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // â”€â”€ TTS: Text-to-Speech via OpenAI â”€â”€
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  let audioCtx = null;
  let audioUnlocked = false;
  let pendingAudioData = null;
  let currentAudioSource = null;

  function ensureAudioCtx() {
    if (!audioCtx) {
      audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      console.log('[tts] AudioContext created, state:', audioCtx.state);
    }
    if (audioCtx.state === 'suspended') {
      audioCtx.resume().then(() => {
        audioUnlocked = true;
        console.log('[tts] AudioContext resumed âœ“');
      });
    } else if (audioCtx.state === 'running') {
      audioUnlocked = true;
    }
  }

  // Unlock audio on first user interaction (required for iOS)
  ['click', 'touchstart', 'keydown'].forEach(evt => {
    document.addEventListener(evt, function unlock() {
      ensureAudioCtx();
      if (pendingAudioData && audioCtx?.state === 'running') {
        const data = pendingAudioData;
        pendingAudioData = null;
        playAudioBuffer(data);
      }
    }, { once: false, passive: true });
  });

  function playAudioBuffer(arrayBuffer) {
    if (!audioCtx || audioCtx.state !== 'running') {
      console.log('[tts] AudioContext not ready, queuing');
      pendingAudioData = arrayBuffer;
      return;
    }

    // Stop any currently playing audio
    if (currentAudioSource) {
      try { currentAudioSource.stop(); } catch {}
      currentAudioSource = null;
    }

    audioCtx.decodeAudioData(arrayBuffer.slice(0), (buffer) => {
      const source = audioCtx.createBufferSource();
      source.buffer = buffer;
      source.connect(audioCtx.destination);
      currentAudioSource = source;

      // Sync mouth animation with audio duration
      if (window.face?.talk) {
        window.face.talk(buffer.duration * 1000);
      }

      source.onended = () => {
        currentAudioSource = null;
        if (window.face?.stop) window.face.stop();
      };

      source.start(0);
      console.log('[tts] Playing audio, duration:', buffer.duration);
    }, (err) => {
      console.error('[tts] decode error:', err);
    });
  }

  async function generateAndPlayTTS(text) {
    if (!hasServer) return;
    try {
      const ttsText = text.length > 500 ? text.slice(0, 500) + '...' : text;
      const resp = await fetch('/speak', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ text: ttsText, voice: 'onyx' }),
      });
      if (!resp.ok) {
        console.error('[tts] server error:', resp.status);
        return;
      }
      const arrayBuffer = await resp.arrayBuffer();
      playAudioBuffer(arrayBuffer);
    } catch (e) {
      console.error('[tts] error:', e);
    }
  }

  // â”€â”€ URL params â”€â”€
  const params = new URLSearchParams(window.location.search);
  const gwUrl = params.get('gw') || '';
  const gwToken = params.get('token') || '';

  // Each device gets its own persistent session via localStorage
  function getSessionKey() {
    const urlKey = params.get('session');
    if (urlKey) return urlKey;
    let key = localStorage.getItem('clawd-face-session');
    if (!key) {
      key = 'face-' + Math.random().toString(36).slice(2, 10);
      localStorage.setItem('clawd-face-session', key);
    }
    return key;
  }
  const sessionKey = getSessionKey();

  // â”€â”€ UI update â”€â”€
  function updateUI() {
    const anyFeature = hasServer || hasGateway;
    bottomBar.classList.toggle('visible', anyFeature);
    demoHint.style.opacity = anyFeature ? '0' : '1';

    // Chat input + send: only when gateway connected
    chatInput.style.display = hasGateway ? 'block' : 'none';
    sendBtn.style.display = hasGateway ? 'flex' : 'none';

    // PTT: only when server running
    pttBtn.style.display = hasServer ? 'flex' : 'none';
  }

  // â”€â”€ Demo mode (click to cycle) â”€â”€
  let demoIndex = 0;
  const allNames = face.list();
  document.body.addEventListener('click', (e) => {
    if (e.target.closest('#bottom-bar, #status-bar')) return;
    demoIndex = (demoIndex + 1) % allNames.length;
    face.set(allNames[demoIndex], 5000);
  });

  // â”€â”€ 1. Detect server.js â”€â”€
  function detectServer() {
    fetch('/health', { signal: AbortSignal.timeout(2000) })
      .then(r => r.json())
      .then(data => {
        if (data.ok) {
          hasServer = true;
          statusServer.textContent = 'Server âœ“';
          statusServer.className = 'status-badge ok';
          statusServer.style.display = '';
          updateUI();
        }
      })
      .catch(() => {
        // Not running via server.js â€” that's fine
      });
  }

  // â”€â”€ 2. Detect & connect Clawdbot gateway â”€â”€
  function detectGateway() {
    if (!gwUrl || !gwToken) return;

    statusGw.textContent = 'Connectingâ€¦';
    statusGw.className = 'status-badge warn';
    statusGw.style.display = '';

    bot = new ClawdbotFace({
      gatewayUrl: gwUrl,
      token: gwToken,
      sessionKey: sessionKey,

      onConnect: () => {
        hasGateway = true;
        statusGw.textContent = 'Gateway âœ“';
        statusGw.className = 'status-badge ok';
        updateUI();
        chatInput.focus();
      },
      onDisconnect: () => {
        hasGateway = false;
        statusGw.textContent = 'Disconnected';
        statusGw.className = 'status-badge err';
        updateUI();
      },
      onMessage: (text) => {
        chatInput.disabled = false;
        sendBtn.disabled = false;

        // Generate and play TTS for bot response
        if (hasServer && text) {
          const cleanText = text.replace(/MEDIA:\S+/g, '').trim();
          if (cleanText) {
            generateAndPlayTTS(cleanText);
          }
        }
      },
      onError: (err) => {
        console.error('[bot]', err);
        chatInput.disabled = false;
        sendBtn.disabled = false;
      },
    });

    bot.connect();
  }

  // â”€â”€ Chat send â”€â”€
  function sendMessage() {
    const text = chatInput.value.trim();
    if (!text || !bot?.connected) return;
    chatInput.value = '';
    chatInput.disabled = true;
    sendBtn.disabled = true;

    // Show user message as bubble
    showBubble(text, Math.max(text.length * 150, 5000));

    bot.send(text);
  }

  chatInput.addEventListener('keydown', (e) => {
    if (e.key === 'Enter') sendMessage();
  });
  sendBtn.addEventListener('click', sendMessage);

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // â”€â”€ Voice Input: Web Speech API + MediaRecorder fallback â”€â”€
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  let recognition = null;
  let isRecording = false;
  let spaceHeld = false;
  let pendingSend = false;

  // MediaRecorder fallback (for iOS or browsers without Web Speech)
  let mediaRecorder = null;
  let audioChunks = [];
  let useMediaRecorder = false;

  // Try to use Web Speech API
  if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    recognition = new SpeechRecognition();
    recognition.lang = navigator.language || 'en-US';
    recognition.interimResults = true;
    recognition.continuous = true;

    recognition.onresult = (event) => {
      let transcript = '';
      let hasFinal = false;
      for (let i = 0; i < event.results.length; i++) {
        transcript = event.results[i][0].transcript;
        if (event.results[i].isFinal) hasFinal = true;
      }

      // Fill input as user speaks (real-time)
      chatInput.value = transcript;

      // If space released and got final result, send
      if (hasFinal && pendingSend) {
        pendingSend = false;
        stopRecording();
        if (transcript.trim()) {
          showBubble(transcript.trim(), Math.max(transcript.length * 150, 5000));
          if (bot?.connected) {
            sendMessage();
          } else {
            if (window.face?.subtitle) face.subtitle(transcript.trim(), 5000);
            if (window.face) face.set('happy', 5000);
          }
        }
      }
    };

    recognition.onerror = (event) => {
      console.log('[speech] error:', event.error);
      pendingSend = false;
      stopRecording();
    };

    recognition.onend = () => {
      // If we were waiting to send but recognition ended, send what we have
      if (pendingSend) {
        pendingSend = false;
        const text = chatInput.value.trim();
        if (text) {
          showBubble(text, Math.max(text.length * 150, 5000));
          if (bot?.connected) {
            sendMessage();
          } else {
            if (window.face?.subtitle) face.subtitle(text, 5000);
            if (window.face) face.set('happy', 5000);
          }
        }
      }
      isRecording = false;
      pttBtn.classList.remove('active');
      pttBtn.textContent = 'ðŸŽ¤';
      chatInput.placeholder = 'Say something...';
    };
  } else {
    // No Web Speech API, use MediaRecorder fallback
    useMediaRecorder = true;
  }

  // â”€â”€ Start recording â”€â”€
  async function startRecording() {
    if (isRecording) return;

    // Pre-unlock AudioContext
    ensureAudioCtx();

    if (useMediaRecorder || !recognition) {
      // MediaRecorder fallback (for iOS)
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaRecorder = new MediaRecorder(stream, {
          mimeType: MediaRecorder.isTypeSupported('audio/webm;codecs=opus')
            ? 'audio/webm;codecs=opus' : 'audio/webm'
        });
        audioChunks = [];
        mediaRecorder.ondataavailable = (e) => {
          if (e.data.size > 0) audioChunks.push(e.data);
        };
        mediaRecorder.onstop = () => {
          stream.getTracks().forEach(t => t.stop());
          transcribeAndSend();
        };
        mediaRecorder.start();
        isRecording = true;
        pttBtn.classList.add('active');
        pttBtn.textContent = 'âº';
        chatInput.placeholder = 'Listening...';
        if (window.face) face.set('alert', 30000);
      } catch (err) {
        console.error('[ptt] mic error:', err);
      }
    } else {
      // Web Speech API
      isRecording = true;
      pttBtn.classList.add('active');
      pttBtn.textContent = 'âº';
      chatInput.placeholder = 'Listening...';
      if (window.face) face.set('alert', 30000);
      try { recognition.start(); } catch {}
    }
  }

  // â”€â”€ Stop recording â”€â”€
  function stopRecording() {
    if (!isRecording) return;

    if (useMediaRecorder || !recognition) {
      if (mediaRecorder && mediaRecorder.state !== 'inactive') {
        mediaRecorder.stop();
      }
    } else {
      // Web Speech: set pendingSend and let onresult/onend handle it
      pendingSend = true;
      try { recognition.stop(); } catch {}
    }

    isRecording = false;
    pttBtn.classList.remove('active');
    pttBtn.textContent = 'ðŸŽ¤';
    chatInput.placeholder = 'Say something...';
  }

  // â”€â”€ MediaRecorder: transcribe via /transcribe endpoint â”€â”€
  async function transcribeAndSend() {
    if (!audioChunks.length) return;
    if (window.face) face.set('thinking', 15000);

    const blob = new Blob(audioChunks, { type: 'audio/webm' });
    try {
      const resp = await fetch('/transcribe', {
        method: 'POST',
        headers: { 'Content-Type': 'audio/webm' },
        body: blob,
      });
      const data = await resp.json();
      const text = data.text?.trim();
      if (!text) {
        if (window.face) face.set('confused', 3000);
        return;
      }

      // Show transcribed text
      chatInput.value = text;
      showBubble(text, Math.max(text.length * 150, 5000));

      // Send if gateway connected
      if (bot?.connected) {
        sendMessage();
      } else {
        if (window.face?.subtitle) face.subtitle(text, 5000);
        if (window.face) face.set('happy', 5000);
      }
    } catch (err) {
      console.error('[ptt] transcribe error:', err);
      if (window.face) face.set('confused', 3000);
    }
  }

  // â”€â”€ PTT Button events â”€â”€
  pttBtn.addEventListener('mousedown', (e) => { e.preventDefault(); startRecording(); });
  pttBtn.addEventListener('mouseup', stopRecording);
  pttBtn.addEventListener('mouseleave', stopRecording);
  pttBtn.addEventListener('touchstart', (e) => { e.preventDefault(); startRecording(); }, { passive: false });
  pttBtn.addEventListener('touchend', (e) => { e.preventDefault(); stopRecording(); });
  pttBtn.addEventListener('touchcancel', stopRecording);

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // â”€â”€ Spacebar Push-to-Talk â”€â”€
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  document.addEventListener('keydown', (e) => {
    if (e.code === 'Space' && !e.repeat) {
      // Don't trigger if typing in input (unless input is focused and empty)
      if (document.activeElement === chatInput && chatInput.value.trim()) {
        return; // Let space type normally
      }
      if (document.activeElement === chatInput) {
        chatInput.blur();
      }
      e.preventDefault();
      if (!spaceHeld && hasServer) {
        spaceHeld = true;
        startRecording();
      }
    }
  });

  document.addEventListener('keyup', (e) => {
    if (e.code === 'Space' && spaceHeld) {
      e.preventDefault();
      spaceHeld = false;
      stopRecording();
    }
  });

  // Prevent space from typing in input during PTT
  chatInput.addEventListener('keydown', (e) => {
    if (e.code === 'Space' && (spaceHeld || isRecording)) {
      e.preventDefault();
      return;
    }
  });

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // â”€â”€ Fullscreen: Press F to toggle â”€â”€
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  function goFullscreen() {
    const el = document.documentElement;
    const req = el.requestFullscreen
      || el.webkitRequestFullscreen
      || el.msRequestFullscreen;
    if (req) req.call(el).catch(() => {});
  }

  function exitFullscreen() {
    const exit = document.exitFullscreen
      || document.webkitExitFullscreen
      || document.msExitFullscreen;
    if (exit) exit.call(document).catch(() => {});
  }

  function isFullscreen() {
    return !!(document.fullscreenElement || document.webkitFullscreenElement);
  }

  function toggleFullscreen() {
    if (isFullscreen()) {
      exitFullscreen();
    } else {
      goFullscreen();
    }
  }

  // F key toggles fullscreen (unless typing in input)
  document.addEventListener('keydown', (e) => {
    if ((e.key === 'f' || e.key === 'F') && document.activeElement !== chatInput) {
      e.preventDefault();
      toggleFullscreen();
    }
  });

  // â”€â”€ Init â”€â”€
  detectServer();
  detectGateway();
})();
</script>

</body>
</html>
